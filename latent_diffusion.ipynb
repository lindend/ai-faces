{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp drive/MyDrive/ai-faces.zip .\n",
    "!unzip ai-faces.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import keras.losses\n",
    "import keras.optimizers\n",
    "import keras.layers as layers\n",
    "import keras.losses as losses\n",
    "import keras.callbacks as callbacks\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_length = 2048\n",
    "embedding_dim = 4\n",
    "image_size = (224, 224)\n",
    "latent_dim_size = (224 // 4, 224 // 4, embedding_dim)\n",
    "beta = 0.25\n",
    "runeager = False\n",
    "small_dataset = True\n",
    "ds_size = 20048\n",
    "batch_size = 32\n",
    "test_size = 5\n",
    "epochs = 1000\n",
    "num_layers = 2\n",
    "# Number of columns in list_attr_celeba.txt\n",
    "num_label_columns = 40\n",
    "\n",
    "steps = 500\n",
    "variance_schedule_start = 0.0001\n",
    "variance_schedule_end = 0.02\n",
    "variance_schedule = [i * (variance_schedule_end - variance_schedule_start) / steps + variance_schedule_start for i in range(steps)]\n",
    "\n",
    "filters = 32\n",
    "\n",
    "version = 1\n",
    "\n",
    "root = \"\"#\"drive/MyDrive/\"\n",
    "\n",
    "img_output_path = f\"{root}generated-latent-diffusion-v{version}\"\n",
    "log_dir = \"logs/latent-diffusion\"\n",
    "model_path = f\"{root}models/latent_diffusion_faces_v{version}.keras\"\n",
    "  \n",
    "if os.path.exists(os.path.join(log_dir, \"train\")):\n",
    "  shutil.rmtree(os.path.join(log_dir, \"train\"))\n",
    "  \n",
    "ae_model_path = f\"{root}models/vqgan_faces_v8.keras\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(layers.Layer):\n",
    "  def call(self, x):\n",
    "    return x * K.sigmoid(x)\n",
    "\n",
    "class GroupNormalization(layers.Layer):\n",
    "  def __init__(self, num_groups = 32, epsilon=1e-7, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.num_groups = num_groups\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    (_, _, _, C) = input_shape\n",
    "    self.channel_weights = self.add_weight(\"channel_weights\", shape=(1, 1, 1, C), initializer=tf.random_uniform_initializer(-1.0, 1.0), trainable=True)\n",
    "    self.channel_biases = self.add_weight(\"channel_biases\", shape=(1, 1, 1, C), initializer=tf.random_uniform_initializer(-1.0, 1.0), trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    (_, W, H, C) = x.shape\n",
    "    B = tf.shape(x)[0]\n",
    "    x = tf.reshape(x, shape=(B, W, H, self.num_groups, C // self.num_groups))\n",
    "    mean, var = tf.nn.moments(x, [1, 2, 4], keepdims=True)\n",
    "    x = (x - mean) / tf.sqrt(var + self.epsilon)\n",
    "    x = tf.reshape(x, shape=(B, W, H, C))\n",
    "    x = x * self.channel_weights + self.channel_biases\n",
    "    return x\n",
    "\n",
    "  def get_config(self):\n",
    "    config = super(GroupNormalization, self).get_config()\n",
    "    config.update({\n",
    "      \"num_groups\": self.num_groups,\n",
    "      \"epsilon\": self.epsilon\n",
    "    })\n",
    "    return config\n",
    "\n",
    "class VectorQuantization(layers.Layer):\n",
    "  def __init__(self, embedding_length, embedding_dim, beta=0.25, **kwargs):\n",
    "    super(VectorQuantization, self).__init__(**kwargs)\n",
    "    self.embedding_length = embedding_length\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.beta = beta\n",
    "    self.embedding = self.add_weight(\"embedding\",\n",
    "      shape=(embedding_length, embedding_dim),\n",
    "      initializer=tf.random_uniform_initializer(-1.0, 1.0), \n",
    "      trainable=True)\n",
    "\n",
    "  def call(self, input):\n",
    "    (_, w, h, c) = input.shape\n",
    "    B = tf.shape(input)[0]\n",
    "    flat = tf.reshape(input, shape=(B * w * h, c))\n",
    "    flat = tf.tile(flat, [1, self.embedding_length])\n",
    "    flat = tf.reshape(flat, shape=(B * w * h, self.embedding_length, c))\n",
    "    diff = tf.pow(flat - self.embedding, 2)\n",
    "    diff = tf.reduce_sum(diff, axis=-1)\n",
    "    embedding_indexes = tf.argmin(diff, axis=-1)\n",
    "    embedding_indexes = tf.reshape(embedding_indexes, shape=(B, w, h))\n",
    "    quantized_vectors = tf.gather(self.embedding, embedding_indexes)\n",
    "\n",
    "    embedding_loss = tf.reduce_mean((tf.stop_gradient(input) - quantized_vectors) ** 2)\n",
    "    encoding_loss = tf.reduce_mean((input - tf.stop_gradient(quantized_vectors)) ** 2)\n",
    "    self.add_loss(embedding_loss + self.beta * encoding_loss)\n",
    "\n",
    "    # Straight through estimator\n",
    "    quantized_vectors = input + tf.stop_gradient(quantized_vectors - input)\n",
    "    return quantized_vectors\n",
    "\n",
    "  def get_config(self):\n",
    "    config = super(VectorQuantization, self).get_config()\n",
    "    config.update({\n",
    "      \"embedding_length\": self.embedding_length,\n",
    "      \"embedding_dim\": self.embedding_dim,\n",
    "      \"beta\": self.beta\n",
    "    })\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 32  896         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " group_normalization (GroupNorm  (None, 224, 224, 32  64         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " swish (Swish)                  (None, 224, 224, 32  0           ['group_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 224, 224, 32  9248        ['swish[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " group_normalization_1 (GroupNo  (None, 224, 224, 32  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " swish_1 (Swish)                (None, 224, 224, 32  0           ['group_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 224, 224, 32  0           ['swish_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 224, 224, 32  9248        ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 224, 224, 32  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 112, 112, 64  18496       ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " group_normalization_2 (GroupNo  (None, 112, 112, 64  128        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " swish_2 (Swish)                (None, 112, 112, 64  0           ['group_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 112, 112, 64  36928       ['swish_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " group_normalization_3 (GroupNo  (None, 112, 112, 64  128        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " swish_3 (Swish)                (None, 112, 112, 64  0           ['group_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 112, 112, 64  0           ['swish_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 112, 112, 64  36928       ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 112, 112, 64  0           ['conv2d_3[0][0]',               \n",
      "                                )                                 'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 56, 56, 128)  73856       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " group_normalization_4 (GroupNo  (None, 56, 56, 128)  256        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " swish_4 (Swish)                (None, 56, 56, 128)  0           ['group_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 56, 56, 128)  147584      ['swish_4[0][0]']                \n",
      "                                                                                                  \n",
      " group_normalization_5 (GroupNo  (None, 56, 56, 128)  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " swish_5 (Swish)                (None, 56, 56, 128)  0           ['group_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 56, 56, 128)  0           ['swish_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 56, 56, 128)  147584      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 56, 56, 128)  0           ['conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (4,)                0           ['add_2[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.tile (TFOpLambda)           (None, 56, 56, 2)    0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 56, 56, 128)  384         ['tf.tile[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 56, 56, 128)  0           ['add_2[0][0]',                  \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 56, 56, 128)  197888     ['add_3[0][0]',                  \n",
      " dAttention)                                                      'add_3[0][0]',                  \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " group_normalization_6 (GroupNo  (None, 56, 56, 128)  256        ['multi_head_attention[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " swish_6 (Swish)                (None, 56, 56, 128)  0           ['group_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 56, 56, 128)  147584      ['swish_6[0][0]']                \n",
      "                                                                                                  \n",
      " group_normalization_7 (GroupNo  (None, 56, 56, 128)  256        ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " swish_7 (Swish)                (None, 56, 56, 128)  0           ['group_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 56, 56, 128)  0           ['swish_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 56, 56, 128)  147584      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 56, 56, 128)  0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " group_normalization_8 (GroupNo  (None, 56, 56, 128)  256        ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " swish_8 (Swish)                (None, 56, 56, 128)  0           ['group_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 56, 4)    4612        ['swish_8[0][0]']                \n",
      "                                                                                                  \n",
      " vector_quantization (VectorQua  (None, 56, 56, 4)   8192        ['conv2d_12[0][0]']              \n",
      " ntization)                                                                                       \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 224, 224, 3)  1257347     ['vector_quantization[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,246,023\n",
      "Trainable params: 2,246,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_objects = {\n",
    "  \"Swish\": Swish,\n",
    "  \"GroupNormalization\": GroupNormalization,\n",
    "  \"VectorQuantization\": VectorQuantization\n",
    "}\n",
    "\n",
    "autoencoder = keras.models.load_model(ae_model_path, custom_objects)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder should not include vector quantization, however the decoder should. conv2d_12 is the last layer before the quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.models.Model(autoencoder.input, autoencoder.get_layer(\"conv2d_12\").output, name=\"encoder\")\n",
    "decoder = keras.models.Model(autoencoder.get_layer(\"vector_quantization\").input, autoencoder.output, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Diffusion(keras.models.Model):\n",
    "  def __init__(self, model,  num_steps, variance_schedule, **kwargs):\n",
    "    super().__init__(kwargs)\n",
    "    self.num_steps = num_steps\n",
    "    self.loss_tracker = keras.metrics.Mean(\"loss\")\n",
    "    self.model = model\n",
    "    self.loss_fn = keras.losses.MSE\n",
    "    self.variance_schedule = variance_schedule\n",
    "    self.alpha = [1 - b for b in variance_schedule]\n",
    "    self.alpha_accumulated = []\n",
    "    total = 1.\n",
    "    for a in self.alpha:\n",
    "      total *= a\n",
    "      self.alpha_accumulated.append(total)\n",
    "\n",
    "  @property\n",
    "  def metrics(self):\n",
    "    return [self.loss_tracker]\n",
    "\n",
    "  def train_step(self, input):\n",
    "    real_images, labels = input\n",
    "    _, width, height, channels = real_images.shape\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    labels = labels[:batch_size]\n",
    "    t = tf.random.uniform(shape=(batch_size,), minval=0, maxval=self.num_steps, dtype=tf.int32)\n",
    "    t_input = t / self.num_steps\n",
    "    input_shape = (batch_size, width, height, channels)\n",
    "    noise = tf.random.normal(shape=input_shape)\n",
    "    alpha_t = tf.gather(self.alpha_accumulated, t)\n",
    "    alpha_t = tf.reshape(alpha_t, shape=(batch_size, 1, 1, 1))\n",
    "    noise_variance = tf.sqrt(1 - alpha_t) * noise\n",
    "    img_median = tf.sqrt(alpha_t) * real_images\n",
    "    noisy_input = img_median + noise_variance\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      predicted_noise = self.model([noisy_input, labels, t_input])\n",
    "      noise_loss = self.loss_fn(noise, predicted_noise)\n",
    "    grads = tape.gradient(noise_loss, self.model.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "    self.loss_tracker.update_state(noise_loss)\n",
    "\n",
    "    return {\n",
    "      \"loss\": self.loss_tracker.result()\n",
    "    }\n",
    "\n",
    "  def sample(self, num_images, labels=None):\n",
    "    result_shape = (num_images, *latent_dim_size)\n",
    "    result = tf.random.normal(shape=result_shape)\n",
    "    for t in reversed(range(1, self.num_steps)):\n",
    "      if t > 1:\n",
    "        z = tf.random.normal(shape=result_shape)\n",
    "      else:\n",
    "        z = tf.zeros(shape=result_shape)\n",
    "      \n",
    "      alpha = self.alpha[t]\n",
    "      alpha_t = self.alpha_accumulated[t]\n",
    "      t_input = tf.constant(t / self.num_steps, dtype=tf.float32)\n",
    "      t_input = tf.broadcast_to(t_input, shape=(num_images,))\n",
    "      # Todo: make 40 not hardcoded\n",
    "      if labels is None:\n",
    "        labels = tf.random.uniform(shape=(num_images, 40), minval=0, maxval=1, dtype=tf.int32)\n",
    "      # Convert to -1 or 1\n",
    "      labels = labels * 2 - 1\n",
    "      predicted_noise = self.model([result, labels, t_input])\n",
    "      noise_factor = (1 - alpha) / tf.sqrt(1 - alpha_t)\n",
    "      sigma = tf.sqrt(self.variance_schedule[t])\n",
    "      result = (1 / tf.sqrt(alpha)) * (result - noise_factor * predicted_noise) + sigma * z\n",
    "\n",
    "    return result\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters):\n",
    "  def inner(x):\n",
    "    x = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def time_embedding_proj(shape, idx, dense_dim=8):\n",
    "  def inner(x):\n",
    "    b, w, h, c = shape\n",
    "    x = layers.Dense(units=dense_dim, activation=\"relu\", name=f\"time_embedding_{idx}_0\")(x)\n",
    "    x = layers.Dense(units=w * h, name=f\"time_embedding_{idx}_1\")(x)\n",
    "    x = layers.Reshape(target_shape=(w, h, 1), name=f\"time_embedding_reshape_{idx}\")(x)\n",
    "    x = layers.Conv2D(filters=c, kernel_size=1, activation=\"relu\", name=f\"time_embedding_{idx}_2\")(x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def downsample():\n",
    "  def inner(x):\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def upsample(filters):\n",
    "  def inner(x):\n",
    "    x = layers.Conv2DTranspose(kernel_size=4, strides=2, filters=filters, padding=\"same\")(x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def dropout(rate):\n",
    "  def inner(x):\n",
    "    x = layers.SpatialDropout2D(rate)(x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def unet_layer(filters, next_layer):\n",
    "  def inner(x, labels, time_embedding, idx=0):\n",
    "    labels = layers.Dense(units=8, name=f\"labels_proj_{idx}\")(labels)\n",
    "    _, w, h, c = x.shape\n",
    "    mapped_labels = layers.Dense(units=w * h, name=f\"map_labels_{idx}\")(labels)\n",
    "    mapped_labels = layers.Reshape(target_shape=(w, h, 1))(mapped_labels)\n",
    "    mapped_labels = layers.Conv2D(filters=c, kernel_size=1, name=f\"conv_labels_{idx}\")(mapped_labels)\n",
    "    x = layers.add([x, mapped_labels])\n",
    "    x = conv_block(filters)(x)\n",
    "    # In bottom layer, do self attention\n",
    "    if next_layer is None:\n",
    "      x = self_attention(3)(x)\n",
    "    x = dropout(0.2)(x)\n",
    "    x = conv_block(filters)(x)\n",
    "    residual = x\n",
    "    if next_layer is not None:\n",
    "      x = downsample()(x)\n",
    "      x = next_layer(x, labels, filters * 2, time_embedding, idx + 1)\n",
    "      x = upsample(filters)(x)\n",
    "      time = time_embedding_proj(x.shape, idx)(time_embedding)\n",
    "      x = layers.add([residual, x, time])\n",
    "      x = conv_block(filters)(x)\n",
    "      x = conv_block(filters)(x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def sublayer(next_layer):\n",
    "  def inner(x, labels, filters, time_embedding, idx):\n",
    "    return unet_layer(filters, next_layer)(x, labels, time_embedding, idx)\n",
    "  return inner\n",
    "\n",
    "def positional_encoding2d():\n",
    "  def inner(inputs):\n",
    "    _, w, h, c = inputs.shape\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    x = tf.range(start=0, limit=w, delta=1)\n",
    "    x = x / w\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "    assert x.shape == (1, w)\n",
    "    x = tf.tile(x, multiples=[h, 1])\n",
    "    assert x.shape == (w, h)\n",
    "    x = tf.reshape(x, shape=(w, h, 1))\n",
    "\n",
    "    y = tf.range(start=0, limit=h, delta=1)\n",
    "    y = y / h\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    assert y.shape == (h, 1)\n",
    "    y = tf.tile(y, [1, w])\n",
    "    assert y.shape == (w, h)\n",
    "    y = tf.reshape(y, shape=(w, h, 1))\n",
    "\n",
    "    indexes = tf.concat([x, y], axis=-1)\n",
    "    assert indexes.shape == (w, h, 2)\n",
    "\n",
    "    indexes = tf.expand_dims(indexes, axis=0)\n",
    "    indexes = tf.tile(indexes, [batch_size, 1, 1, 1])\n",
    "\n",
    "    return layers.Conv2D(c, kernel_size=1, strides=1, padding=\"same\")(indexes)\n",
    "    # Todo: the sinusoidal way from All you need is attention\n",
    "  return inner\n",
    "\n",
    "def self_attention(num_heads=1, key_dim=64):\n",
    "  def inner(x):\n",
    "    # add positional encoding?\n",
    "    pos = positional_encoding2d()(x)\n",
    "    x = layers.add([x, pos])\n",
    "    x = layers.MultiHeadAttention(num_heads, key_dim, attention_axes=(2, 3))(x, x, x)\n",
    "    return x\n",
    "  return inner\n",
    "\n",
    "def cross_attention(num_heads=1, key_dim=64):\n",
    "  def inner(qk, v):\n",
    "    pos_qk = positional_encoding2d()(qk)\n",
    "    pos_v = positional_encoding2d()(v)\n",
    "    qk = layers.add([qk, pos_qk])\n",
    "    v = layers.add([v, pos_v])\n",
    "    return layers.MultiHeadAttention(num_heads, key_dim, attention_axes=(2, 3))(qk, v, qk)\n",
    "  return inner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(num_labels, filters):\n",
    "  if os.path.exists(model_path):\n",
    "    return keras.models.load_model(model_path)\n",
    "\n",
    "  w, h, c = latent_dim_size\n",
    "  image_input = keras.Input(shape=(w, h, c), name=\"images\")\n",
    "  t_input = keras.Input(shape=(1,), name=\"t_input\")\n",
    "  label_input = keras.Input(shape=(num_labels,), name=\"labels\")\n",
    "  sublayers = sublayer(None)\n",
    "  for i in range(num_layers):\n",
    "    sublayers = sublayer(sublayers)\n",
    "\n",
    "  x = unet_layer(filters, sublayers)(image_input, label_input, t_input)\n",
    "  output = layers.Conv2D(filters=embedding_dim, kernel_size=3, padding=\"same\")(x)\n",
    "  model = keras.Model([image_input, label_input, t_input], output)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiffusionMonitor(keras.callbacks.Callback):\n",
    "  def __init__(self, decoder, num_img=3):\n",
    "    self.num_img = num_img\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    generated_images = self.model.sample(self.num_img)\n",
    "    generated_images = self.decoder(generated_images)\n",
    "    if not os.path.exists(img_output_path):\n",
    "      os.mkdir(img_output_path)\n",
    "\n",
    "    for i in range(self.num_img):\n",
    "      img = keras.utils.array_to_img(generated_images[i])\n",
    "      img.save(os.path.join(img_output_path, f\"generated_{epoch:03d}_{i}.png\"))\n",
    "\n",
    "class Save(keras.callbacks.Callback):\n",
    "  def __init__(self, model_path):\n",
    "    self.model_path = model_path\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.model.model.save(self.model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " labels (InputLayer)            [(None, 40)]         0           []                               \n",
      "                                                                                                  \n",
      " labels_proj_0 (Dense)          (None, 8)            328         ['labels[0][0]']                 \n",
      "                                                                                                  \n",
      " map_labels_0 (Dense)           (None, 3136)         28224       ['labels_proj_0[0][0]']          \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 56, 56, 1)    0           ['map_labels_0[0][0]']           \n",
      "                                                                                                  \n",
      " images (InputLayer)            [(None, 56, 56, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " conv_labels_0 (Conv2D)         (None, 56, 56, 4)    8           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 56, 56, 4)    0           ['images[0][0]',                 \n",
      "                                                                  'conv_labels_0[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 56, 56, 32)   1184        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " labels_proj_1 (Dense)          (None, 8)            72          ['labels_proj_0[0][0]']          \n",
      "                                                                                                  \n",
      " spatial_dropout2d (SpatialDrop  (None, 56, 56, 32)  0           ['conv2d[0][0]']                 \n",
      " out2D)                                                                                           \n",
      "                                                                                                  \n",
      " map_labels_1 (Dense)           (None, 784)          7056        ['labels_proj_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 56, 56, 32)   9248        ['spatial_dropout2d[0][0]']      \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 28, 28, 1)    0           ['map_labels_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 28, 28, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv_labels_1 (Conv2D)         (None, 28, 28, 32)   64          ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 28, 28, 32)   0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv_labels_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 64)   18496       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " labels_proj_2 (Dense)          (None, 8)            72          ['labels_proj_1[0][0]']          \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (SpatialDr  (None, 28, 28, 64)  0           ['conv2d_2[0][0]']               \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " map_labels_2 (Dense)           (None, 196)          1764        ['labels_proj_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 64)   36928       ['spatial_dropout2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 14, 14, 1)    0           ['map_labels_2[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv_labels_2 (Conv2D)         (None, 14, 14, 64)   128         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 14, 14, 64)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv_labels_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 14, 14, 128)  73856       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " labels_proj_3 (Dense)          (None, 8)            72          ['labels_proj_2[0][0]']          \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (SpatialDr  (None, 14, 14, 128)  0          ['conv2d_4[0][0]']               \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " map_labels_3 (Dense)           (None, 49)           441         ['labels_proj_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 14, 14, 128)  147584      ['spatial_dropout2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 7, 7, 1)      0           ['map_labels_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 128)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv_labels_3 (Conv2D)         (None, 7, 7, 128)    256         ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 7, 7, 128)    0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv_labels_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 7, 7, 256)    295168      ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOpLamb  (4,)                0           ['conv2d_6[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.tile_2 (TFOpLambda)         (None, 7, 7, 2)      0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 7, 7, 256)    768         ['tf.tile_2[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 7, 7, 256)    0           ['conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " t_input (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 7, 7, 256)   197440      ['add_4[0][0]',                  \n",
      " dAttention)                                                      'add_4[0][0]',                  \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " time_embedding_2_0 (Dense)     (None, 8)            16          ['t_input[0][0]']                \n",
      "                                                                                                  \n",
      " spatial_dropout2d_3 (SpatialDr  (None, 7, 7, 256)   0           ['multi_head_attention[0][0]']   \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " time_embedding_2_1 (Dense)     (None, 196)          1764        ['time_embedding_2_0[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 256)    590080      ['spatial_dropout2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " time_embedding_reshape_2 (Resh  (None, 14, 14, 1)   0           ['time_embedding_2_1[0][0]']     \n",
      " ape)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 14, 14, 128)  524416     ['conv2d_8[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " time_embedding_2_2 (Conv2D)    (None, 14, 14, 128)  256         ['time_embedding_reshape_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 14, 14, 128)  0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_transpose[0][0]',       \n",
      "                                                                  'time_embedding_2_2[0][0]']     \n",
      "                                                                                                  \n",
      " time_embedding_1_0 (Dense)     (None, 8)            16          ['t_input[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 14, 14, 128)  147584      ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " time_embedding_1_1 (Dense)     (None, 784)          7056        ['time_embedding_1_0[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 14, 14, 128)  147584      ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " time_embedding_reshape_1 (Resh  (None, 28, 28, 1)   0           ['time_embedding_1_1[0][0]']     \n",
      " ape)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 28, 28, 64)  131136      ['conv2d_10[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " time_embedding_1_2 (Conv2D)    (None, 28, 28, 64)   128         ['time_embedding_reshape_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 28, 28, 64)   0           ['conv2d_3[0][0]',               \n",
      "                                                                  'conv2d_transpose_1[0][0]',     \n",
      "                                                                  'time_embedding_1_2[0][0]']     \n",
      "                                                                                                  \n",
      " time_embedding_0_0 (Dense)     (None, 8)            16          ['t_input[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 28, 28, 64)   36928       ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " time_embedding_0_1 (Dense)     (None, 3136)         28224       ['time_embedding_0_0[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 28, 28, 64)   36928       ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " time_embedding_reshape_0 (Resh  (None, 56, 56, 1)   0           ['time_embedding_0_1[0][0]']     \n",
      " ape)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 56, 56, 32)  32800       ['conv2d_12[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " time_embedding_0_2 (Conv2D)    (None, 56, 56, 32)   64          ['time_embedding_reshape_0[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 56, 56, 32)   0           ['conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_transpose_2[0][0]',     \n",
      "                                                                  'time_embedding_0_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 56, 56, 32)   9248        ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 56, 56, 32)   9248        ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 56, 56, 4)    1156        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,523,805\n",
      "Trainable params: 2,523,805\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = get_model(num_label_columns, filters)\n",
    "model.summary()\n",
    "\n",
    "diffusion = Diffusion(model, steps, variance_schedule)\n",
    "diffusion.compile(optimizer=\"rmsprop\", run_eagerly=runeager)\n",
    "\n",
    "callbacks = [\n",
    "  DiffusionMonitor(decoder),\n",
    "  Save(model_path)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1299 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fname = os.path.join(\"list_attr_celeba.txt\")\n",
    "\n",
    "with open(fname) as f:\n",
    "  data = f.read()\n",
    "\n",
    "lines = data.split(\"\\n\")\n",
    "header = lines[1].split()\n",
    "lines = lines[2:-1]\n",
    "raw_data = np.zeros((len(lines), len(header)))\n",
    "for i, line in enumerate(lines):\n",
    "  line_data = [int(x) for x in line.split()[1:]]\n",
    "  raw_data[i, :] = line_data[:]\n",
    "\n",
    "label_dataset = tf.data.Dataset.from_tensor_slices(raw_data).batch(batch_size)\n",
    "image_dataset = keras.utils.image_dataset_from_directory(\n",
    "  f\"img_align_celeba{'_small' if small_dataset else ''}\",\n",
    "  label_mode=None,\n",
    "  image_size=image_size,\n",
    "  batch_size=batch_size,\n",
    "  smart_resize=True,\n",
    "  shuffle=False)\n",
    "\n",
    "image_dataset = image_dataset.map(lambda x: x / (255. / 2) - 1.)\n",
    "image_dataset = image_dataset.map(lambda x: encoder(x))\n",
    "\n",
    "dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "dataset = dataset.take(ds_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8144WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "41/41 [==============================] - 345s 8s/step - loss: 0.8144\n",
      "Epoch 2/1000\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5421WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "41/41 [==============================] - 319s 8s/step - loss: 0.5421\n",
      "Epoch 3/1000\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4419WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "41/41 [==============================] - 314s 8s/step - loss: 0.4419\n",
      "Epoch 4/1000\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3856WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "41/41 [==============================] - 310s 8s/step - loss: 0.3856\n",
      "Epoch 5/1000\n",
      "28/41 [===================>..........] - ETA: 1:34 - loss: 0.3405"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\ai-faces\\latent_diffusion.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/ai-faces/latent_diffusion.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m diffusion\u001b[39m.\u001b[39;49mfit(dataset, callbacks\u001b[39m=\u001b[39;49mcallbacks, epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "diffusion.fit(dataset, callbacks=callbacks, epochs=epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32f2fe102a4f10662d8c13f75131e1ba377b7194060421a642fdea27c55fc65a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
